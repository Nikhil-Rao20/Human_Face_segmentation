{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_qTipexjAKz"
      },
      "source": [
        "# Training the UNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo7Zaq6fxc7G"
      },
      "source": [
        "## Mounting the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTJTKiTGr4YD",
        "outputId": "8028c3d4-5903-4a6c-a4fa-403184da82a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JJM4wjsrxPGK"
      },
      "outputs": [],
      "source": [
        "drive_path = '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvnzYEjIjAK0"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EQk4hTUajAK1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation ,MaxPool2D, Conv2DTranspose, Concatenate, Input, UpSampling2D, MultiHeadAttention, LayerNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Lp4S6FjOz0"
      },
      "source": [
        "### Seeding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "saofWBpxjAK1"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEoTOczRjfuL"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EDn-P5rAjbTH"
      },
      "outputs": [],
      "source": [
        "batch_size=4\n",
        "lr=1e-4\n",
        "epochs=5\n",
        "height=768\n",
        "width=512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "OwA2Q66WjoI0"
      },
      "outputs": [],
      "source": [
        "dataset_path = os.path.join(drive_path, \"Human Face Segmentation\", \"Original_Data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3PHoS_5XkgGH"
      },
      "outputs": [],
      "source": [
        "files_dir = os.path.join(drive_path, 'Colab Notebooks', 'Files', 'Original_Data')\n",
        "model_file_unet = os.path.join(files_dir, \"unet-org.h5\")\n",
        "model_file_basic_trans = os.path.join(files_dir, \"basic-trans-org.h5\")\n",
        "model_file_adv_trans = os.path.join(files_dir, \"adv-trans-org.h5\")\n",
        "log_file = os.path.join(files_dir, \"log-aug.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2KQgZMFjvwh"
      },
      "source": [
        "### Creating Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "zrxxReNXjsYa"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "aCS4ONbij20B"
      },
      "outputs": [],
      "source": [
        "create_dir(files_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0NveGmhlJgS"
      },
      "source": [
        "## Building UNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAE6lCjKlgFD"
      },
      "source": [
        "### Conv Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZV7Tme7nlADY"
      },
      "outputs": [],
      "source": [
        "def conv_block(inputs, num_filters, strides=1):\n",
        "    x = Conv2D(num_filters, 3,strides=strides, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfq1hNZ5liZL"
      },
      "source": [
        "### Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HTpyV4Y1leNZ"
      },
      "outputs": [],
      "source": [
        "def encoder_block(inputs, num_filters):\n",
        "    x=conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2,2))(x)\n",
        "\n",
        "    return x,p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyZoYAJlxgL"
      },
      "source": [
        "### Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fx_bJSoqlnG5"
      },
      "outputs": [],
      "source": [
        "def decoder_block(inputs, skip, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same')(inputs)\n",
        "    x=Concatenate()([x,skip])\n",
        "    x = conv_block(x,num_filters)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhPEf9ITmIzK"
      },
      "source": [
        "### UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-_ucU4xMmIBb"
      },
      "outputs": [],
      "source": [
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\"ENCODER\"\"\"\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    \"\"\"Bridge\"\"\"\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    \"\"\"Decoder\"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1,1,padding='same', activation='sigmoid')(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1V8EZB-GyIj"
      },
      "source": [
        "### TransUNet Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PNMUt8NFGyIj"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, num_heads=4, ff_dim=64, num_transformer_layers=12, dropout_rate=0.1):\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_layers):\n",
        "        # Multi-Head Self-Attention\n",
        "        attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=64)(x, x)\n",
        "        x = LayerNormalization(epsilon=1e-6)(attn_output + x)\n",
        "\n",
        "        # Feed Forward Network\n",
        "        ffn = Conv2D(filters=ff_dim, kernel_size=1, activation='relu')(x)\n",
        "        ffn = Conv2D(filters=inputs.shape[-1], kernel_size=1)(ffn)\n",
        "        x = LayerNormalization(epsilon=1e-6)(ffn + x)\n",
        "\n",
        "        # Dropout\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "pnur4DIGGyIj"
      },
      "outputs": [],
      "source": [
        "def trans_encoder(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolution layer\n",
        "    x=conv_block(inputs, num_filters=64)\n",
        "\n",
        "    # Encoder blocks with transformers\n",
        "    encoder_blocks = [\n",
        "        conv_block(x, 64),\n",
        "        conv_block(x, 128, strides=2),  # Downsample\n",
        "        transformer_encoder(x),  # 12 transformer layers\n",
        "        conv_block(x, 256, strides=2),  # Downsample\n",
        "        transformer_encoder(x),  # 12 transformer layers\n",
        "        conv_block(x, 512,\n",
        "                   strides=2),  # Downsample\n",
        "        transformer_encoder(x),  # 12 transformer layers\n",
        "    ]\n",
        "\n",
        "    return inputs, encoder_blocks[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKnS8RNzGyIj"
      },
      "source": [
        "### TransUNet Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9QMx95uJGyIk"
      },
      "outputs": [],
      "source": [
        "def trans_decoder(encoder_output, num_classes=2):\n",
        "    x = encoder_output\n",
        "\n",
        "    # Decoder blocks with upsampling\n",
        "    decoder_blocks = [\n",
        "        Conv2D(512, 3, activation='relu', padding='same')(x),\n",
        "        UpSampling2D()(x),\n",
        "        Conv2D(256, 3, activation='relu', padding='same')(x),\n",
        "        UpSampling2D()(x),\n",
        "        Conv2D(128, 3, activation='relu', padding='same')(x),\n",
        "        UpSampling2D()(x),\n",
        "        Conv2D(64, 3, activation='relu', padding='same')(x),\n",
        "        UpSampling2D()(x),\n",
        "    ]\n",
        "\n",
        "    # Final segmentation output\n",
        "    output = Conv2D(num_classes, 1, activation='softmax')(x)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDmsqZUFGyIk"
      },
      "source": [
        "## TransUNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "KDh8Oid7GyIk"
      },
      "outputs": [],
      "source": [
        "def basic_trans_unet(input_shape, num_classes):\n",
        "    inputs, encoder_output = trans_encoder(input_shape)\n",
        "    decoder_output = trans_decoder(encoder_output, num_classes)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=decoder_output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nikhil's TransUNet"
      ],
      "metadata": {
        "id": "cAOpM2Z1LQPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trans_unet_encoder(inputs, num_filters):\n",
        "    x=conv_block(inputs, num_filters)\n",
        "    x = transformer_encoder(x,num_transformer_layers=12)\n",
        "    p = MaxPool2D((2,2))(x)\n",
        "    return x,p\n",
        "\n",
        "def trans_unet_decoder(inputs, skip, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2,2), strides=2, padding='same')(inputs)\n",
        "    x=Concatenate()([x,skip])\n",
        "    x = conv_block(x,num_filters)\n",
        "    return x\n",
        "\n",
        "def adv_trans_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\"ENCODER\"\"\"\n",
        "    s1, p1 = trans_unet_encoder(inputs, 64)\n",
        "    s2, p2 = trans_unet_encoder(p1, 128)\n",
        "    s3, p3 = trans_unet_encoder(p2, 256)\n",
        "    s4, p4 = trans_unet_encoder(p3, 512)\n",
        "\n",
        "    \"\"\"Bridge\"\"\"\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    \"\"\"Decoder\"\"\"\n",
        "    d1 = trans_unet_decoder(b1, s4, 512)\n",
        "    d2 = trans_unet_decoder(d1, s3, 256)\n",
        "    d3 = trans_unet_decoder(d2, s2, 128)\n",
        "    d4 = trans_unet_decoder(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1,1,padding='same', activation='softmax')(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"TRANSUNET\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "DgO29fLoLPcB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "191KiZTFN40_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
        "    return (2.0 * intersection + smooth) / (union + smooth)"
      ],
      "metadata": {
        "id": "SiMIlLnON4G1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Godlv_eZo_DU"
      },
      "source": [
        "### Dataset Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MtxiEiMeoica"
      },
      "outputs": [],
      "source": [
        "#Loading the training and validation dataset\n",
        "def load_data(path):\n",
        "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*\")))\n",
        "    train_y = sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\")))\n",
        "\n",
        "\n",
        "    valid_x = sorted(glob(os.path.join(path, \"valid\", \"images\", \"*\")))\n",
        "    valid_y = sorted(glob(os.path.join(path, \"valid\", \"masks\", \"*\")))\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sqUgzL2wpjaH"
      },
      "outputs": [],
      "source": [
        "# Reading Images\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "    x=x/255.0\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2rjWGso_puei"
      },
      "outputs": [],
      "source": [
        "# Reading Mask\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = x/255.0\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iKVxypdwp8Mo"
      },
      "outputs": [],
      "source": [
        "# tf.data pipeline\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)  # Use read_mask instead of read_image for masks\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
        "    x.set_shape([height, width, 3])\n",
        "    y.set_shape([height, width, 1])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def tf_dataset(x,y,batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UQh_RzHqvXf"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE3tNLSDqthR",
        "outputId": "5c48c95b-9bb0-472c-81ad-f4bb7d2c96bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train : 108 - 108\n",
            "Valid : 13 - 13\n"
          ]
        }
      ],
      "source": [
        "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
        "print(f\"Train : {len(train_x)} - {len(train_y)}\")\n",
        "print(f\"Valid : {len(valid_x)} - {len(valid_y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "X8Jqg4OnrAoW"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2NJZdwsrPzW",
        "outputId": "0f94fc4a-7e03-4b86-e6e4-2d35372b9527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 768, 512, 3) (4, 768, 512, 1)\n",
            "(4, 768, 512, 3) (4, 768, 512, 1)\n",
            "(4, 768, 512, 3) (4, 768, 512, 1)\n",
            "(1, 768, 512, 3) (1, 768, 512, 1)\n"
          ]
        }
      ],
      "source": [
        "for x, y in valid_dataset:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8JWgAEL2rj-z"
      },
      "outputs": [],
      "source": [
        "input_shape = (height, width,3)\n",
        "unet_model = build_unet(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "YtEYnpa_GyIm"
      },
      "outputs": [],
      "source": [
        "basic_trans_model = basic_trans_unet(input_shape, num_classes=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_trans_model = adv_trans_unet(input_shape)"
      ],
      "metadata": {
        "id": "MlNwe0ykMlGE"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "r472BgSVsCnK"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(lr)\n",
        "unet_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', dice_coefficient])\n",
        "basic_trans_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy' , dice_coefficient])\n",
        "adv_trans_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', dice_coefficient])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "cz3XNr-2sifW"
      },
      "outputs": [],
      "source": [
        "callbacks_unet=[\n",
        "    ModelCheckpoint(model_file_unet, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    CSVLogger(log_file),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
        "]\n",
        "callbacks_basic_trans=[\n",
        "    ModelCheckpoint(model_file_basic_trans, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    CSVLogger(log_file),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
        "]\n",
        "callbacks_adv_trans=[\n",
        "    ModelCheckpoint(model_file_adv_trans, verbose=1, save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
        "    CSVLogger(log_file),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z4IINNxs7wv"
      },
      "outputs": [],
      "source": [
        "unet_model.fit(train_dataset,\n",
        "          validation_data=valid_dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks_unet\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_fN7W3w0UHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d1fee8-9ac7-450b-cf5d-a8661449ce5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        }
      ],
      "source": [
        "basic_trans_model.fit(train_dataset,\n",
        "          validation_data=valid_dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks_basic_trans\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_trans_model.fit(train_dataset,\n",
        "          validation_data=valid_dataset,\n",
        "          epochs=epochs,\n",
        "          callbacks=callbacks_adv_trans\n",
        "          )"
      ],
      "metadata": {
        "id": "4zerTEh9OtIz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}